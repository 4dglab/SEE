{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1cecd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import anndata\n",
    "import cooler\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from typing import List, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dec689ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_workers = 48\n",
    "\n",
    "def get_duo(thelist: List[Union[pd.DataFrame, pd.Series]]) -> Union[pd.Series, List[pd.Series]]:\n",
    "    \"\"\"Yields a pair of elements from a given list, or one element if only one element is present.\"\"\"\n",
    "    if len(thelist) == 0:\n",
    "        raise ValueError(\"No element to yield!\")\n",
    "    if len(thelist) < 2:\n",
    "        return thelist[0]\n",
    "    length = len(thelist)\n",
    "    for j in range(0, length, 2):\n",
    "        if j >= len(thelist):\n",
    "            return\n",
    "        if j == len(thelist) - 1:\n",
    "            yield thelist[-1]\n",
    "        else:\n",
    "            duo = thelist[j : j + 2]\n",
    "            yield duo\n",
    "\n",
    "\n",
    "def concat(duo: Union[pd.DataFrame, Union[pd.DataFrame, pd.Series]]) -> Union[pd.Series, pd.DataFrame]:\n",
    "    if isinstance(duo, list):\n",
    "        return pd.concat([duo[0], duo[1]], axis=1)\n",
    "    else:\n",
    "        return duo\n",
    "\n",
    "\n",
    "def fast_concat(features: List) -> pd.DataFrame:\n",
    "    while len(features) != 1:\n",
    "        with ThreadPool(processes=max_workers) as pool:\n",
    "            features = list(pool.imap_unordered(concat, get_duo(features)))\n",
    "    features = features[0]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd0913e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Using backend LokyBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=48)]: Done 104 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=48)]: Done 354 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=48)]: Done 704 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=48)]: Done 1154 tasks      | elapsed:   26.9s\n",
      "[Parallel(n_jobs=48)]: Done 1704 tasks      | elapsed:   39.2s\n",
      "[Parallel(n_jobs=48)]: Done 2354 tasks      | elapsed:   53.5s\n",
      "[Parallel(n_jobs=48)]: Done 3104 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=48)]: Done 3954 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=48)]: Done 4238 out of 4238 | elapsed:  1.6min finished\n"
     ]
    }
   ],
   "source": [
    "folder_path = '/home/micl/workspace/lmh_data/Lee2019/Human_single_cell_10kb_cool'\n",
    "\n",
    "parallel = Parallel(n_jobs=max_workers, backend='loky', verbose=1)\n",
    "\n",
    "def load_coolers(folder_path):\n",
    "    def load_cooler(folder_path, file_name):\n",
    "        c = cooler.Cooler(os.path.join(folder_path, file_name))\n",
    "        contact = c.pixels(join=True)[:]\n",
    "        contact = contact[contact['chrom1']==contact['chrom2']]\n",
    "        binsize, chromsizes = c.binsize, c.chromsizes\n",
    "        \n",
    "        concat = contact[['chrom1', 'start1', 'start2', 'count']]\n",
    "        concat = concat.rename(columns={'chrom1':'chrom', 'start1':'start', 'start2':'end'})\n",
    "        concat = concat.set_index(['chrom', 'start', 'end'])\n",
    "\n",
    "        return concat.astype('int').rename(columns={'count':file_name})\n",
    "\n",
    "    joblist = []\n",
    "    for root, dirs, files in os.walk(folder_path, topdown=False):\n",
    "        for file_name in files:\n",
    "            joblist.append(delayed(load_cooler)(folder_path, file_name))\n",
    "\n",
    "    infos = parallel(joblist)\n",
    "    infos = fast_concat(infos)\n",
    "    infos = infos.fillna(0).sort_index()\n",
    "#     infos = pd.concat(infos, axis=1).fillna(0).sort_index()\n",
    "    return infos\n",
    "\n",
    "infos = load_coolers(folder_path)\n",
    "infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9763ceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = pd.DataFrame(infos.T.index, columns=['cells'])\n",
    "obs.insert(obs.shape[1] - 1, 'domain', 'scHiC')\n",
    "obs = obs.set_index('cells')\n",
    "var = infos.reset_index()[['chrom', 'start']].set_index(infos.index.map('{0[0]}_{0[1]}'.format))\n",
    "\n",
    "infos.index = infos.index.map('{0[0]}_{0[1]}'.format)\n",
    "infos = anndata.AnnData(X=infos.T, obs=obs, var=var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f59a01f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# infos.write(\"/home/micl/workspace/lmh_data/Lee2019/scHiC.h5ad\", compression=\"gzip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sclab",
   "language": "python",
   "name": "sclab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
